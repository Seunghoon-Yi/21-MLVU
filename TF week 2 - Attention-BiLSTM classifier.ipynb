{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8434240237218707000,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11000905728\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14896714155916300689\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size = 25000\n",
      "test data size = 25000\n",
      "num_class = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000                                    # Maximum word numbers in our dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
    "print(f\"training data size = {len(X_train)}\")\n",
    "print(f\"test data size = {len(X_test)}\")\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print(f\"num_class = {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean len = 238.71364, 2-sigma len = 407.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "len_review = [len(r) for r in X_train]\n",
    "len_2sig = np.quantile(len_review, 0.865)\n",
    "print(f\"Mean len = {np.mean(len_review)}, 2-sigma len = {len_2sig}\")  # 2-sigma length cover\n",
    "plt.boxplot(len_review);plt.show()\n",
    "\n",
    "print(X_train[0])  # Embedded words. low number means high frequency, 0,1,2,3 == specialized tokens. \n",
    "word2idx = imdb.get_word_index()\n",
    "idx2word = {}\n",
    "for key, val in word2idx.items():\n",
    "    idx2word[val+3] = key         # value+3 = real mapping integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent : the\n",
      "least frequent : 'l'\n",
      "88587\n",
      "<sos> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <unk> romance <unk> on to the scene <unk> <unk> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <unk> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <unk> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <unk> sent to prison for fraud he is put in a cell with three others the quietly insane <unk> body building <unk> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <unk> after <unk> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <unk> makes the best of it's <unk> as despite it's <unk> the film never actually feels restrained and manages to flow well throughout director eric <unk> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <unk> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <unk> people and this film proves that as the director <unk> that we can never really be sure of exactly what is round the corner and this helps to ensure that <unk> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <unk> is a truly great horror film and one of the best of the decade highly recommended viewing\n"
     ]
    }
   ],
   "source": [
    "print(f\"most frequent : {idx2word[4]}\")\n",
    "print(f\"least frequent : {idx2word[max(idx2word.keys())]}\")\n",
    "print(max(idx2word.keys()))\n",
    "# An example of how the IMDB data looks like\n",
    "for idx, token in enumerate ([\"<pad>\", \"<sos>\", \"<unk>\"]):\n",
    "    idx2word[idx] = token\n",
    "print(' '.join([idx2word[idx] for idx in X_train[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "\n",
    "l_max = int(len_2sig) ; print(l_max)\n",
    "X_train = pad_sequences(X_train, maxlen = l_max)\n",
    "X_test = pad_sequences(X_test, maxlen = l_max)       # Now all of the reviews are set in len_2sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ The bahdanau attention ------#\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()  \n",
    "        # super(The current class name, self). super : execute tf.keras.Model.__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)     \n",
    "        self.V = Dense(1)          # With no activation specification, act = linear\n",
    "    def call(self, val, query):\n",
    "        # query : dim = N*h (N = batch, h = hidden size)\n",
    "        h_t = tf.expand_dims(query, 1)\n",
    "        # Decoder hidden(t). expand dims in axis = 1\n",
    "        \n",
    "        # Attn score : dim = N*h*1(h : )\n",
    "        score = self.V(tf.nn.tanh(self.W1(val) + self.W2(h_t)))\n",
    "        # Dense(units) : output = dim(N, units). So this works as a weight matrix. \n",
    "        \n",
    "        # Attn weights : dim = N*d_model*1\n",
    "        weight = tf.nn.softmax(score, axis = 1) # d_model direction calc.\n",
    "        \n",
    "        # Context vec, N*()\n",
    "        weighted_vec = weight*val            \n",
    "        weighted_vec = tf.reduce_sum(weighted_vec, axis = 1)\n",
    "        \n",
    "        return weighted_vec, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ The BiLSTM layer ------#\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 407, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "seq_ipt = Input(shape = (l_max,), dtype = 'int32')\n",
    "embedded_seq = Embedding(vocab_size, 64, input_length = l_max, mask_zero = True)(seq_ipt)\n",
    "# 16384 wores -> 128dim embedding\n",
    "# mask_zero = True : mask layers with zeros(<--확인해볼것!)\n",
    "\n",
    "# 1st layer, N_cells = 64\n",
    "Bilstm = Bidirectional(LSTM(64, dropout = 0.5, return_sequences = True))(embedded_seq)\n",
    "# Check dims\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(Bilstm)\n",
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input shape :** N(batch), 462?(max_l = **Timesteps**), 96(word embed = **input dim**)<br>\n",
    "hidden, cell dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 407)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 407, 64)      640000      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 407, 128)     66048       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) [(None, 407, 128), ( 98816       bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           bidirectional_6[0][1]            \n",
      "                                                                 bidirectional_6[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention_2 (BahdanauA ((None, 128), (None, 16577       bidirectional_6[0][0]            \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 20)           2580        bahdanau_attention_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            21          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 824,042\n",
      "Trainable params: 824,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "98/98 [==============================] - 556s 6s/step - loss: 0.6161 - accuracy: 0.6221 - val_loss: 0.3099 - val_accuracy: 0.8704\n",
      "Epoch 2/2\n",
      "98/98 [==============================] - 538s 6s/step - loss: 0.2580 - accuracy: 0.9132 - val_loss: 0.2858 - val_accuracy: 0.8801\n"
     ]
    }
   ],
   "source": [
    "# Concatenate each fwd / bwd state\n",
    "hidden_ = Concatenate()([forward_h, backward_h])\n",
    "cell_   = Concatenate()([forward_c, backward_c])\n",
    "# Attn, with units = hidden dim\n",
    "Attn = BahdanauAttention(64)\n",
    "context_vector, attention_weights = Attn(lstm, hidden_)\n",
    "\n",
    "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
    "model = Model(inputs=seq_ipt, outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 2, batch_size = 256, \\\n",
    "                    validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 466s 596ms/step - loss: 0.2858 - accuracy: 0.8801\n",
      "Accuracy : 0.8801\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful tips : <br>\n",
    "**1. .join // https://blockdmask.tistory.com/468<br>**\n",
    "<code>'_'.join(['a', 'small', 'example'])\n",
    "</code>\n",
    "returns \"a_small_example\"<br><br>\n",
    "**2. tf to_categorical(x, num_classes = n)**<br>\n",
    "returns one-hot encoded n classes in n dimension<br><br>\n",
    "**3. tf pad_sequence(X, )**<br>\n",
    "basically pad to the largest dimension of the data<br><br>\n",
    "**4. tf.expand_dims?**<br>\n",
    "transpose를 해서 (Batch)X(size,) -> (Batch)X(1,size)로 맞추기 위해 <br>\n",
    "**5. LSTM outputs**<br>\n",
    "lstm = LSTM(n_units, return_seq = False, return_st = False)(input) : returns only the last hidden st<br>\n",
    "return_seq = False, return_st = True : last hidden st, last hidden st, last cell st<br>\n",
    "return_seq = True, return_st = True : All sequence hidden st, last hidden st, last cell st<br>\n",
    "https://simpling.tistory.com/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bi, fwd_h, fwd_c, bwd_h, bwd_c =\\\n",
    "Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(embedded_seq)\n",
    "print(test_bi.shape, fwd_h.shape, fwd_c.shape, bwd_h.shape, bwd_c.shape)\n",
    "\n",
    "test_single, h, c = LSTM(64, dropout=0.5, return_sequences=True, return_state=True)(embedded_seq)\n",
    "print(test_single.shape, h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. layers.Dense()**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.random((3,4,5));print(A)\n",
    "test_ipt = Input(shape = (A.shape), dtype = 'float32')\n",
    "dense_test = Dense(10,activation = 'relu')(test_ipt)\n",
    "dense_test_ = Dense(1)(dense_test)\n",
    "model_test = Model(inputs = test_ipt, outputs = dense_test_)\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that the Input(X) shape  =  (a,b,c), Dense layer = Dense(d).<br>\n",
    "Then W = (c, d), where WX = np.tensordot(X, W, [-1], [0]). Hence contracting through the **last axis of the input** and **the first axis of W(weight mtx or the Kernel of the layer)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
